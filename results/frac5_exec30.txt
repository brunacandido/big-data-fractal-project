[INFO] Loading 4000/80000 files (5.0%)

[INFO] Loading data from s3a://ubs-datasets/FRACTAL/data/val/ with file fraction=0.05
[INFO] Loading 500/10000 files (5.0%)

[INFO] Loading data from s3a://ubs-datasets/FRACTAL/data/test/ with file fraction=0.05
[INFO] Loading 500/10000 files (5.0%)
[INFO] Data repartitioned to 240 partitions
Fitting preprocessing pipeline...

============< Validation Accuracy >============
numTrees=10 → acc=0.7867
numTrees=20 → acc=0.7837
numTrees=30 → acc=0.7861

Best: numTrees=10 (acc=0.7867)

TEST ACCURACY: 0.7697

============< Task Metrics >============

Scheduling mode = FIFO
Spark Context default degree of parallelism = 60

Aggregated Spark task metrics:
numTasks => 22537
successful tasks => 22537
speculative tasks => 0
taskDuration => 61934523 (17.2 h)
schedulerDelayTime => 166712 (2.8 min)
executorRunTime => 61461109 (17.1 h)
executorCpuTime => 42390198 (11.8 h)
executorDeserializeTime => 303428 (5.1 min)
executorDeserializeCpuTime => 106289 (1.8 min)
resultSerializationTime => 3274 (3 s)
jvmGCTime => 2229980 (37 min)
shuffleFetchWaitTime => 8227 (8 s)
shuffleWriteTime => 154103 (2.6 min)
gettingResultTime => 0 (0 ms)
resultSize => 5604 (5.5 KB)
diskBytesSpilled => 0 (0 Bytes)
memoryBytesSpilled => 0 (0 Bytes)
peakExecutionMemory => 647115065869
recordsRead => 12608361334
bytesRead => 1352323795679 (1259.4 GB)
recordsWritten => 0
bytesWritten => 0 (0 Bytes)
shuffleRecordsRead => 6634432424
shuffleTotalBlocksFetched => 1042192
shuffleLocalBlocksFetched => 35016
shuffleRemoteBlocksFetched => 1007176
shuffleTotalBytesRead => 220489025402 (205.3 GB)
shuffleLocalBytesRead => 7425394153 (6.9 GB)
shuffleRemoteBytesRead => 213063631249 (198.4 GB)
shuffleRemoteBytesReadToDisk => 0 (0 Bytes)
shuffleBytesWritten => 220489025402 (205.3 GB)
shuffleRecordsWritten => 6634432424
Job finished.